# Taurscribe

**High-Performance Real-Time Transcription Engine**

Taurscribe is a **local-first, privacy-focused** speech-to-text application built with Rust and Tauri. It delivers real-time transcription using OpenAI's Whisper model with GPU acceleration (CUDA/Vulkan), achieving latency competitive with cloud servicesâ€”all without sending your audio data to external servers.

## ğŸ¯ Project Vision

> *"Fast, Practical, Local, Private: Beat commercial cloud latency with bare-metal Rust + Whisper"*

Taurscribe aims to rival commercial cloud services in transcription speed and accuracy while keeping all processing entirely on your machine. No internet required, no data leaks, no API costs.

---

## ğŸ—ï¸ Architecture Overview

Taurscribe uses a **dual-transcription pipeline** for optimal user experience:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND (React + Vite)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Start Button â”‚                        â”‚ Stop Button  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                       â”‚
          â”‚ invoke("start_recording")             â”‚ invoke("stop_recording")
          â”‚                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (Rust + Tauri)                    â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            Audio Input Stream (cpal)               â”‚     â”‚
â”‚  â”‚         [Microphone â†’ f32 samples @ 48kHz]        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                                    â”‚               â”‚
â”‚        â”‚ Stereo                             â”‚ Mono          â”‚
â”‚        â–¼                                    â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Thread 1â”‚                      â”‚    Thread 2    â”‚      â”‚
â”‚  â”‚   WAV    â”‚                      â”‚    WHISPER     â”‚      â”‚
â”‚  â”‚  Writer  â”‚                      â”‚  (Real-Time)   â”‚      â”‚
â”‚  â”‚          â”‚                      â”‚                â”‚      â”‚
â”‚  â”‚ Saves    â”‚                      â”‚ â€¢ Buffers 6s   â”‚      â”‚
â”‚  â”‚ Full     â”‚                      â”‚ â€¢ Converts     â”‚      â”‚
â”‚  â”‚ Quality  â”‚                      â”‚   48â†’16kHz     â”‚      â”‚
â”‚  â”‚ Audio    â”‚                      â”‚ â€¢ Transcribes  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚ â€¢ Prints live  â”‚      â”‚
â”‚                                    â”‚   to console   â”‚      â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            ON STOP: Final Transcription            â”‚     â”‚
â”‚  â”‚  1. Close channels â†’ flush threads                 â”‚     â”‚
â”‚  â”‚  2. Load saved WAV file                            â”‚     â”‚
â”‚  â”‚  3. Run high-quality transcription on full file    â”‚     â”‚
â”‚  â”‚  4. Return final transcript to frontend            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚          Whisper Manager (whisper.rs)              â”‚     â”‚
â”‚  â”‚  â€¢ GPU Auto-Detection (CUDA â†’ Vulkan â†’ CPU)       â”‚     â”‚
â”‚  â”‚  â€¢ Model: ggml-base.en-q5_0.bin                    â”‚     â”‚
â”‚  â”‚  â€¢ Context history for better accuracy             â”‚     â”‚
â”‚  â”‚  â€¢ Automatic resampling (any rate â†’ 16kHz)         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© How It Works

### 1. **Audio Capture** (`lib.rs`)

When you click **Start Recording**:

- Uses `cpal` to access your system microphone
- Creates a real-time audio stream (typically 48kHz stereo)
- Spawns **two parallel processing threads** via `crossbeam-channel`

### 2. **Dual Processing Pipeline**

#### **Thread 1: File Writer**
- Receives **stereo** audio samples (L/R channels intact)
- Writes to WAV file using `hound` crate
- Preserves full quality for final transcription
- Finishes when `stop_recording` is called

#### **Thread 2: Live Transcription**
- Receives **mono** audio (stereo mixed to single channel)
  - *Why?* Whisper interprets stereo as 2Ã— speed, causing hallucinations
- Buffers 6-second chunks (balancing speed vs. accuracy)
  - *Why 6s?* 3s clips cause sentence cuts â†’ "Our evidence is a key" errors
- Resamples 48kHz â†’ 16kHz using `rubato`
- Feeds to Whisper for transcription
- Prints live results to console

### 3. **Whisper Transcription** (`whisper.rs`)

The `WhisperManager` handles all AI processing:

```rust
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      WhisperManager::initialize()       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Load model from disk                 â”‚
â”‚    (taurscribe-runtime/models/)         â”‚
â”‚                                         â”‚
â”‚ 2. Try GPU acceleration:                â”‚
â”‚    âœ“ CUDA (NVIDIA RTX 4070)            â”‚
â”‚    âœ“ Vulkan (AMD 780M/any GPU)         â”‚
â”‚    âœ“ CPU (fallback)                    â”‚
â”‚                                         â”‚
â”‚ 3. Suppress C++ logs                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WhisperManager::transcribe_chunk()    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT: f32 samples, sample_rate         â”‚
â”‚                                         â”‚
â”‚ 1. Resample to 16kHz (if needed)       â”‚
â”‚ 2. Create Whisper state                â”‚
â”‚ 3. Set params:                          â”‚
â”‚    â€¢ Language: English                  â”‚
â”‚    â€¢ Threads: 4                         â”‚
â”‚    â€¢ Context: Previous transcript       â”‚
â”‚ 4. Run inference                        â”‚
â”‚ 5. Extract segments                     â”‚
â”‚ 6. Return text + performance metrics    â”‚
â”‚                                         â”‚
â”‚ OUTPUT: String (transcribed text)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WhisperManager::transcribe_file()     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT: WAV file path                    â”‚
â”‚                                         â”‚
â”‚ 1. Load WAV with hound                  â”‚
â”‚ 2. Convert stereo â†’ mono               â”‚
â”‚ 3. Resample to 16kHz in chunks          â”‚
â”‚ 4. Run full transcription               â”‚
â”‚ 5. Return complete transcript           â”‚
â”‚                                         â”‚
â”‚ OUTPUT: High-quality final text         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. **Memory Safety**

Rust's ownership system ensures:
- No data races between threads
- Automatic cleanup when recording stops
- Type-safe communication via channels

The `crossbeam-channel` crate provides:
```rust
let (tx, rx) = unbounded::<Vec<f32>>();
tx.send(samples)?;  // Thread-safe send
rx.recv()?;         // Thread-safe receive
```

### 5. **GPU Acceleration**

Built with `whisper-rs` featuring:
- **CUDA**: NVIDIA RTX cards (fastest)
- **Vulkan**: Universal GPU support (AMD, Intel, NVIDIA)
- **CPU**: Automatic fallback

The backend auto-selects the best available option at runtime.

---

## ğŸ“Š Available Models

Taurscribe supports multiple Whisper models located in `taurscribe-runtime/models/`:

| Model Name | Size | Speed (RTX 4070) | Use Case | Currently Used |
|------------|------|------------------|----------|----------------|
| **ggml-tiny.en.bin** | 75 MB | ~0.15s | Ultra-fast, lower accuracy | âŒ |
| **ggml-base.en-q5_0.bin** | 52 MB | ~0.37s | **Recommended** - Best balance | âœ… **Active** |
| **ggml-base.en.bin** | 142 MB | ~0.45s | Good balance of speed/quality | âŒ |
| **ggml-small.en.bin** | 487 MB | ~1.2s | High accuracy, slower | âŒ |
| **ggml-large-v3.bin** | 3.0 GB | ~3.5s | Maximum accuracy | âŒ |
| **ggml-silero-v6.2.0.bin** | 864 KB | N/A | Voice Activity Detection (VAD) | âŒ |

### Model Details

#### **Currently Active: `ggml-base.en-q5_0.bin`**
- **Accuracy**: 97% of base.en quality
- **Speed**: 0.37s for 11s audio (~30Ã— realtime)
- **Size**: 3Ã— smaller than base.en
- **Best for**: Production deployment - fast, accurate, small

#### **Maximum Quality: `ggml-large-v3.bin`**
- **Accuracy**: Best available (multilingual, 1550M parameters)
- **Speed**: 3.5s for 11s audio on RTX 4070 (~3.1Ã— realtime)
- **RAM**: ~6-8 GB during inference
- **Best for**: Maximum transcription quality

#### **Speed Demon: `ggml-tiny.en.bin`**
- **Accuracy**: Basic transcription
- **Speed**: 0.15s for 11s audio (~73Ã— realtime)
- **Best for**: Testing, prototyping

#### **Voice Activity Detection: `ggml-silero-v6.2.0.bin`**
- **Purpose**: Detect speech vs. silence
- **Use**: Can optimize by skipping silent chunks

### Switching Models

To change the active model, edit `src-tauri/src/whisper.rs`:

```rust
// Line 60
let model_path = "taurscribe-runtime/models/ggml-base.en-q5_0.bin";  // Change this
```

Or for dynamic selection (future feature), implement model switching via Tauri commands.

---

## ğŸš€ Getting Started

### Prerequisites

- **Rust** (1.70+): [Install](https://rustup.rs/)
- **Node.js** (18+): [Install](https://nodejs.org/)
- **GPU Drivers** (optional but recommended):
  - NVIDIA: CUDA Toolkit 11.8+
  - AMD/Intel: Latest Vulkan drivers

### Installation

```bash
# Clone repository
git clone https://github.com/Abdullahu5mani/Taurscribe.git
cd Taurscribe

# Install frontend dependencies
npm install

# Download Whisper models (if not included)
# Models go in: taurscribe-runtime/models/
# Download from: https://huggingface.co/ggerganov/whisper.cpp
```

### Development

```bash
# Run in development mode (hot reload for frontend, auto-recompile for Rust)
npm run tauri dev
# or with bun:
bun run tauri dev
```

**Performance Tips:**
- âš¡ **First run is slow** (~2-5 min) - compiling whisper-rs with CUDA/Vulkan
- ğŸ”¥ **Keep it running!** - Frontend changes hot-reload instantly
- ğŸ¦€ **Rust changes** - Only recompile what changed (~10-30s)
- ğŸ’¡ **Don't restart** unless you change Cargo.toml dependencies

### Production Build

```bash
# Build optimized executable
npm run tauri build
```

Output: `src-tauri/target/release/taurscribe.exe`

---

## ğŸ§ª Testing

### 1. **Basic Recording Test**
1. Launch the app
2. Click **Start Recording**
3. Speak clearly: *"This is a test of the Taurscribe transcription system"*
4. Click **Stop Recording**
5. Check console for live transcription + final output

### 2. **Console Output Example**

```
[INFO] Initializing Whisper transcription engine...
[INFO] Loading Whisper model from disk: 'C:\...\ggml-base.en-q5_0.bin'
[GPU] Attempting GPU acceleration...
[SUCCESS] âœ“ GPU acceleration enabled (CUDA)
[INFO] Backend: CUDA
[INFO] Warming up GPU...
[INFO] GPU warm-up complete

[INFO] Whisper thread started
[PROCESSING] Transcribing 6.00s chunk (288000 samples)...
[PERF] Processed 6.00s audio in 370ms | Speed: 16.2x
[TRANSCRIPT] "This is a test"

[INFO] Recording stopped, processing remaining audio...
[PROCESSING] Running final high-quality transcription on: recording_1737280323.wav
[FINAL_TRANSCRIPT]
This is a test of the Taurscribe transcription system.
```

### 3. **Performance Benchmarks**

On **NVIDIA RTX 4070** + **AMD Ryzen 9 7940HS**:

| Model | Cold Start | Warm Encode | Total (11s audio) | Realtime Factor |
|-------|-----------|-------------|-------------------|-----------------|
| base.en-q5_0 (CUDA) | 0.22s | 0.15s | 0.37s | 30Ã— |
| large-v3 (CUDA) | 1.85s | 1.65s | 3.50s | 3.1Ã— |
| tiny.en (CUDA) | 0.08s | 0.07s | 0.15s | 73Ã— |

See `BENCHMARK_RESULTS.md` for detailed metrics.

---

## ğŸ“ Project Structure

```
Taurscribe/
â”œâ”€â”€ src/                         # Frontend (React + TypeScript)
â”‚   â”œâ”€â”€ App.tsx                  # Main UI component
â”‚   â”œâ”€â”€ App.css                  # Styles
â”‚   â””â”€â”€ main.tsx                 # Entry point
â”‚
â”œâ”€â”€ src-tauri/                   # Backend (Rust)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib.rs               # Audio recording + Tauri commands
â”‚   â”‚   â””â”€â”€ whisper.rs           # Whisper transcription engine
â”‚   â”œâ”€â”€ Cargo.toml               # Rust dependencies
â”‚   â””â”€â”€ tauri.conf.json          # Tauri configuration
â”‚
â”œâ”€â”€ taurscribe-runtime/          # Whisper binaries & models
â”‚   â”œâ”€â”€ bin/                     # whisper.exe executables + DLLs
â”‚   â”œâ”€â”€ models/                  # GGML model files (.bin)
â”‚   â””â”€â”€ samples/                 # Test audio (jfk.wav)
â”‚
â”œâ”€â”€ package.json                 # Node.js dependencies
â”œâ”€â”€ vite.config.ts               # Vite bundler config
â””â”€â”€ README.md                    # This file
```

---

## ğŸ”§ Key Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Framework** | [Tauri 2.0](https://tauri.app/) | Lightweight Rust + Web UI |
| **Frontend** | React 19 + Vite | Modern reactive UI |
| **Audio** | [cpal](https://github.com/RustAudio/cpal) | Cross-platform audio I/O |
| **AI Model** | [whisper-rs](https://github.com/tazz4843/whisper-rs) | Rust bindings for Whisper.cpp |
| **GPU** | CUDA + Vulkan | Hardware acceleration |
| **Resampling** | [rubato](https://github.com/HEnquist/rubato) | High-quality audio resampling |
| **WAV I/O** | [hound](https://github.com/ruuda/hound) | WAV file reading/writing |
| **Threading** | [crossbeam](https://github.com/crossbeam-rs/crossbeam) | Lock-free concurrent channels |

---

## ğŸ›ï¸ Configuration

### Audio Settings

Edit `src-tauri/src/lib.rs`:

```rust
// Chunk size (line 99)
let chunk_size = (sample_rate * 6) as usize;  // 6 seconds

// Max buffer (line 100)
let max_buffer_size = chunk_size * 2;  // 12 seconds total

// Thread count for Whisper (whisper.rs line 149)
params.set_n_threads(4);
```

### Whisper Parameters

Edit `src-tauri/src/whisper.rs`:

```rust
// Language (line 151)
params.set_language(Some("en"));  // "en", "es", "fr", etc.

// Model path (line 60)
let model_path = "taurscribe-runtime/models/ggml-base.en-q5_0.bin";

// GPU toggle (line 66)
params.use_gpu(true);  // false to force CPU
```

---

## ğŸ› Troubleshooting

### **"No input device"**
- **Cause**: Microphone not connected or permissions denied
- **Fix**: Check Windows Privacy Settings â†’ Microphone â†’ Allow desktop apps

### **"Failed to initialize Whisper"**
- **Cause**: Model file missing or corrupted
- **Fix**: Re-download model from [Hugging Face](https://huggingface.co/ggerganov/whisper.cpp)
- **Path**: Must be in `taurscribe-runtime/models/`

### **"GPU failed" / Fallback to CPU**
- **Cause**: Missing GPU drivers or unsupported GPU
- **Fix**: 
  - NVIDIA: Install [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
  - AMD/Intel: Update graphics drivers for Vulkan support
- **Workaround**: CPU mode still works, just slower

### **Hallucinations** ("Thank you for watching!", random text)
- **Cause**: Silent audio or background noise
- **Fix**:
  1. Ensure microphone is working (`recording_*.wav` should have actual audio)
  2. Reduce chunk size (line 99 in `lib.rs`)
  3. Use Voice Activity Detection (VAD) to skip silence

### **Slow Transcription**
- **Cause**: Using large model on CPU
- **Solutions**:
  1. Switch to smaller model (`base.en-q5_0`)
  2. Enable GPU acceleration
  3. Reduce thread count if thermal throttling

---

## ğŸš§ Known Limitations

1. **Model switching requires code edit** (no GUI selector yet)
2. **No persistent storage** (transcripts only shown in console)
3. **English-only optimization** (multilingual support exists but untested)
4. **Windows-only tested** (Linux/macOS should work but unverified)

---

## ğŸ—ºï¸ Roadmap

- [x] Real-time audio capture
- [x] GPU-accelerated transcription
- [x] Dual-pipeline live + final transcription
- [x] GPU backend detection (CUDA/Vulkan/CPU)
- [ ] **GUI model selector**
- [ ] **Save transcripts to file**
- [ ] **Export to TXT/SRT/VTT**
- [ ] **Voice Activity Detection integration**
- [ ] **WebSocket frontend updates** (replace console logs)
- [ ] **macOS/Linux support**
- [ ] **Installer packaging**

---

## ğŸ“„ License

This project is open-source under the MIT License.

**Third-Party Components:**
- Whisper.cpp: MIT License
- Tauri: MIT/Apache 2.0
- All Rust crates: See individual licenses in `Cargo.toml`

---

## ğŸ™ Acknowledgments

- **OpenAI** for Whisper
- **Georgi Gerganov** for [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
- **tazz4843** for [whisper-rs](https://codeberg.org/tazz4843/whisper-rs)
- **Tauri Team** for the amazing framework

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/Abdullahu5mani/Taurscribe/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Abdullahu5mani/Taurscribe/discussions)

---

**Built with â¤ï¸ using Rust and Tauri**
